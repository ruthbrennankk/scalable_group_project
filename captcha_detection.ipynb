{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captcha_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthbrennankk/scalable_group_project/blob/master/captcha_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP7l_S8Bax1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi30LY3zCvY3"
      },
      "source": [
        "!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "!pip install captcha\n",
        "!pip install stsci.ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hrYMIRvCwRN"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import scipy.ndimage\n",
        "import random\n",
        "import captcha.image\n",
        "\n",
        "from PIL import Image\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDkPlwlhV5e"
      },
      "source": [
        "# captcha_symbols=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#[]+:></%{}\" # I didn't see it in mine but potentially '\\'\n",
        "captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\-|_ \" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfxS5RzBerO"
      },
      "source": [
        "# Preprocess\n",
        "def preprocess(raw_data) :\n",
        "    return smallPreprocess(raw_data)\n",
        "\n",
        "def erase_circles(img, circles):\n",
        "    circles = circles[0]  # hough circles returns a nested list for some reason\n",
        "    for circle in circles:\n",
        "        center = (round(circle[0]),round(circle[1]))\n",
        "        img = cv2.circle(img, center, radius=round(circle[2]), color=255, thickness=1)  # erase circle by making it white (to match the image background)\n",
        "    return img\n",
        "\n",
        "def detect_and_remove_circles(img):\n",
        "    hough_circle_locations = cv2.HoughCircles(img, method=cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=5, minRadius=0, maxRadius=2)\n",
        "    if hough_circle_locations is not None:\n",
        "        img = erase_circles(img, hough_circle_locations)\n",
        "    return img\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def pyPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    # image = np.array(img) / 255.0\n",
        "    image = np.array(img, dtype=np.float32) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def bigPreprocess(raw_data) :\n",
        "    #   Back to Black\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "    # run some basic tests to get rid of easy-to-remove noise -- first pass\n",
        "    img = ~img  # white letters, black background\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # weaken circle noise and line noise\n",
        "    img = ~img  # black letters, white background\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # remove line noise\n",
        "    img = scipy.ndimage.median_filter(img, (1, 3))  # weaken circle noise\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = scipy.ndimage.median_filter(img, (3, 3))  # remove any final 'weak' noise that might be present (line or circle)\n",
        "    # detect any remaining circle noise\n",
        "    img = detect_and_remove_circles(img)  # after dilation, if concrete circles exist, use hough transform to remove them\n",
        "    # eradicate any final noise that wasn't removed previously -- second pass\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # actually performs erosion\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # finally completely remove any extra noise that remains\n",
        "    img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=2)  # dilate image to make it look like the original\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    #Edge Detection\n",
        "    # img = cv2.Canny(img, 100, 200)\n",
        "    # Back to Colour\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Format - (different for pi)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    return image.reshape([-1, c, h, w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct97WoykCWlG"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "def main():\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6\n",
        "    #Train\n",
        "    # count = 160000 #160000 - 10m 58s #16000 - 1m 6s #100 - 0s\n",
        "    # output_dir = '/content/train_set' # image set\n",
        "    # outputFile = '/content/train_labels.txt' #  labels\n",
        "    # #Val\n",
        "    # count = 16000 #160000 - 10m 58s #16000 - 1m 6s #100 - 0s\n",
        "    # output_dir = '/content/val_set' # image set\n",
        "    # outputFile = '/content/val_labels.txt' #  labels\n",
        "    # #Test\n",
        "    count = 100 #160000 - 10m 58s #16000 - 1m 6s #100 - 0s\n",
        "    output_dir = '/content/test_set' # image set\n",
        "    outputFile = '/content/test_labels.txt' #  labels\n",
        "\n",
        "    captcha_symbols=\"%{}[]()#:><+-|_1234567890ABCDFMPQRSTUVWXYZecghjknx\" \n",
        "\n",
        "    for x in range(0, 15):\n",
        "      captcha_symbols = captcha_symbols + ' '\n",
        "\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols) for j in range(caplength)])\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = np.array(captcha_generator.generate_image(random_str))\n",
        "        cv2.imwrite(image_path, image)\n",
        "        with open(outputFile,'+a') as f:\n",
        "            random_str.strip()\n",
        "            f.write(img_name + \",\" + random_str.replace(\" \", \"\") + \"\\n\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dI9wdAiCqTY"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "def main():\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6\n",
        "    count = 1000 #100 #140800 #128000 - 40m\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/test_set' #test set\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/train_set' #training set\n",
        "    outputFile = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/training_lables'\n",
        "    output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set' #validation set\n",
        "    # Appedning symbol set with \\ and -\n",
        "    captcha_symbols=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#[]+:></%{}\\-\" # I didn't see it in mine but potentially '\\'    # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/symbols.txt'\n",
        "    # for x in range(0, 9):\n",
        "    #   captcha_symbols = captcha_symbols + ' '\n",
        "\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols) for j in range(caplength)])\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(args.output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(args.output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = np.array(captcha_generator.generate_image(random_str))\n",
        "        cv2.imwrite(image_path, image)\n",
        "        with open(outputFile,'+a') as f:\n",
        "            f.write(img_name + \", \" + random_str + \"\\n\")\n",
        "\n",
        "    # for i in range(count):\n",
        "    #     random_str = ''.join([random.choice(captcha_symbols) for j in range(length)])\n",
        "\n",
        "    #     filenames.append(random_str)\n",
        "\n",
        "    #     image_path = os.path.join(output_dir, str(index)+'.png')\n",
        "        \n",
        "    #     if os.path.exists(image_path):\n",
        "    #         version = 1\n",
        "    #         while os.path.exists(os.path.join(output_dir, str(index) + '_' + str(version) + '.png')):\n",
        "    #             version += 1\n",
        "    #         image_path = os.path.join(output_dir, str(index) + '_' + str(version) + '.png')\n",
        "\n",
        "    #     image = np.array(captcha_generator.generate_image(random_str))\n",
        "    #     cv2.imwrite(image_path, image)\n",
        "    #     index = index + 1\n",
        "\n",
        "    # pd.DataFrame(filenames).to_csv(\"/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set_names.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANHumMjC0l6"
      },
      "source": [
        "# Train\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Build a Keras model given some parameters\n",
        "def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):\n",
        "  input_tensor = keras.Input(input_shape)\n",
        "  x = input_tensor\n",
        "  for i, module_length in enumerate([module_size] * model_depth):\n",
        "      for j in range(module_length):\n",
        "          x = keras.layers.Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "          x = keras.layers.BatchNormalization()(x)\n",
        "          x = keras.layers.Activation('relu')(x)\n",
        "      x = keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = [keras.layers.Dense(captcha_num_symbols, activation='softmax', name='char_%d'%(i+1))(x) for i in range(captcha_length)]\n",
        "  model = keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "  return model\n",
        "\n",
        "# A Sequence represents a dataset for training in Keras\n",
        "# In this case, we have a folder full of images\n",
        "# Elements of a Sequence are *batches* of images, of some size batch_size\n",
        "class ImageSequence(keras.utils.Sequence):\n",
        "    def __init__(self, directory_name, label_file, batch_size, captcha_length, captcha_symbols, captcha_width, captcha_height):\n",
        "        self.directory_name = directory_name\n",
        "        self.batch_size = batch_size\n",
        "        self.captcha_length = captcha_length\n",
        "        self.captcha_symbols = captcha_symbols\n",
        "        self.captcha_width = captcha_width\n",
        "        self.captcha_height = captcha_height\n",
        "        with open(label_file,\"+r\") as f:\n",
        "          labelList = f.readlines()\n",
        "          self.labels = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "        file_list = os.listdir(self.directory_name)\n",
        "        self.files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "        self.used_files = []\n",
        "        self.count = len(file_list)\n",
        "        print('dir name ' + self.directory_name + '/n')\n",
        "        print(self.count)\n",
        "        # print(self.files['img_90160'])\n",
        "        # print(self.labels)\n",
        "        # random_image_label = self.labels['img_1.png'].split('_')[0]\n",
        "        # print(random_image_label)\n",
        "        # print(self.files['img_2'])\n",
        "        # if len(random_image_label) < self.captcha_length :\n",
        "        #     balance = self.captcha_length - len(random_image_label)\n",
        "        #     for x in range(0, balance) :\n",
        "        #       random_image_label = random_image_label + ' '\n",
        "        # for j, ch in enumerate(random_image_label):\n",
        "        #   print(random_image_label)\n",
        "        #   print(j)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.count / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = np.zeros((self.batch_size, self.captcha_height, self.captcha_width, 3), dtype=np.float32)\n",
        "        y = [np.zeros((self.batch_size, len(self.captcha_symbols)), dtype=np.uint8) for i in range(self.captcha_length)]\n",
        "\n",
        "        for i in range(min(self.batch_size, len(self.files))):\n",
        "            random_image_name = random.choice(list(self.labels.keys()))\n",
        "            random_image_label = self.labels[random_image_name]\n",
        "            random_image_file = self.files[random_image_name[:-4]]\n",
        "\n",
        "            # We've used this image now, so we can't repeat it in this iteration\n",
        "            self.used_files.append(self.files.pop(random_image_name[:-4]))\n",
        "            self.labels.pop(random_image_name)\n",
        "\n",
        "            # We have to scale the input pixel values to the range [0, 1] for\n",
        "            # Keras so we divide by 255 since the image is 8-bit RGB\n",
        "            raw_data = cv2.imread(os.path.join(self.directory_name, random_image_file))\n",
        "            processed_data = preprocess(raw_data)\n",
        "            X[i] = processed_data\n",
        "\n",
        "            random_image_label = random_image_label.split('_')[0]\n",
        "            if len(random_image_label) < self.captcha_length :\n",
        "              balance = self.captcha_length - len(random_image_label)\n",
        "              for x in range(0, balance) :\n",
        "                random_image_label = random_image_label + ' '\n",
        "            \n",
        "            # print(random_image_label)\n",
        "            for j, ch in enumerate(random_image_label):\n",
        "                # print('i ' + str(i))\n",
        "                # print('j ' + str(j))\n",
        "                y[j][i, :] = 0\n",
        "                y[j][i, self.captcha_symbols.find(ch)] = 1\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def main():\n",
        "    # inputs\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6 \n",
        "    # symbols = 'symbols.txt'\n",
        "    batch_size = 32\n",
        "    epochs = 2 #8\n",
        "    train_dataset = '/content/train_set/'\n",
        "    train_labels_file = '/content/train_labels.txt'\n",
        "    validate_dataset = '/content/val_set/'\n",
        "    val_labels_file = '/content/val_labels.txt'\n",
        "    output_model_name = '/content/train_model_10'\n",
        "    input_model = output_model_name #None\n",
        "\n",
        "    # captcha_symbols = None\n",
        "    # with open(symbols) as symbols_file:\n",
        "    #     captcha_symbols = symbols_file.readline()\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "\n",
        "        model = create_model(length, len(captcha_symbols), (height, width, 3))\n",
        "\n",
        "        if input_model is not None:\n",
        "            model.load_weights('/content/train_model_09'+'.h5')\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        # test_data = ImageSequence('/content/drive/MyDrive/Practical 2/test_set/', '/content/drive/MyDrive/Practical 2/test_labels.txt', 32, 6, \"avnjbafibu\", 128, 64)\n",
        "        training_data = ImageSequence(train_dataset, train_labels_file, batch_size, length, captcha_symbols, width, height)\n",
        "        validation_data = ImageSequence(validate_dataset, val_labels_file, batch_size, length, captcha_symbols, width, height)\n",
        "\n",
        "        callbacks = [keras.callbacks.EarlyStopping(patience=3),\n",
        "                      # keras.callbacks.CSVLogger('log.csv'),\n",
        "                      keras.callbacks.ModelCheckpoint(output_model_name+'.h5', save_best_only=False)]\n",
        "\n",
        "        # Save the model architecture to JSON\n",
        "        with open(output_model_name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(model.to_json())\n",
        "\n",
        "        try:\n",
        "            model.fit_generator(generator=training_data,\n",
        "                                validation_data=validation_data,\n",
        "                                epochs=epochs,\n",
        "                                callbacks=callbacks,\n",
        "                                use_multiprocessing=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyboardInterrupt caught, saving current weights as ' + output_model_name+'_resume.h5')\n",
        "            model.save_weights(output_model_name+'_resume.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IcKsswbLGJK"
      },
      "source": [
        "#   Classify\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    model_name = '/content/train_model_09'\n",
        "    captcha_dir = '/content/test_set/'\n",
        "    # captcha_dir = '/content/drive/MyDrive/Ruth/brennar5_imgs'\n",
        "    label_file = '/content/test_labels.txt'\n",
        "    output = '/content/classify_train_model_05_output.csv'\n",
        "    # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "    labels = None\n",
        "    with open(label_file,\"+r\") as f:\n",
        "      labelList = f.readlines()\n",
        "      labels = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "\n",
        "    # print(labels['img_0.png'])\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        with open(output, 'w') as output_file:\n",
        "            json_file = open(model_name+'.json', 'r')\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            model = keras.models.model_from_json(loaded_model_json)\n",
        "            model.load_weights(model_name+'.h5')\n",
        "            # model.load_weights('/content/drive/MyDrive/Practical 2/train_model_01'+'_resume'+'.h5')\n",
        "            # model.load_weights(model_name+'_resume.h5')\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                          metrics=['accuracy'])\n",
        "            \n",
        "\n",
        "\n",
        "            for x in os.listdir(captcha_dir):\n",
        "                # load image and preprocess it\n",
        "                raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "\n",
        "                #   Preprocess Image\n",
        "                image = preprocess(raw_data)\n",
        "\n",
        "                prediction = model.predict(image)\n",
        "                predictedAnswer = decode(captcha_symbols, prediction)\n",
        "                output_file.write(x + \", \" + predictedAnswer + \"\\n\")\n",
        "                predictedAnswer.strip()\n",
        "                predictedAnswer = predictedAnswer.replace(\" \", \"\")\n",
        "                # predictedAnswer = predictedAnswer.replace(\"_\", \"\")\n",
        "\n",
        "                # answer = x[:-4]\n",
        "                answer = labels.get(x)\n",
        "                print('Classified ' + x + ' ' + answer + '///' + predictedAnswer)\n",
        "                if (answer == predictedAnswer) :\n",
        "                    correct = correct + 1\n",
        "                    print('^ CORRECT ^')\n",
        "                else :\n",
        "                    incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVVklkiDGy_"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Converter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def main(model_name):\n",
        "    with open(f'/content/{model_name}.json') as f:\n",
        "        model = f.read()\n",
        "    model = keras.models.model_from_json(model)\n",
        "    model.load_weights(f'/content/{model_name}.h5')\n",
        "    cvt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite = cvt.convert()\n",
        "    with open(f'/content/converted_{model_name}.tflite', 'wb') as f:\n",
        "        f.write(tflite)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = 'train_model_09'\n",
        "    main(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D5HK4YIc-t"
      },
      "source": [
        "# Classify - Lite\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=1)\n",
        "    #y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    \n",
        "    model_name = '/content/converted_train_model_09.tflite'\n",
        "    # captcha_dir = '/content/test_set'\n",
        "    captcha_dir = '/content/drive/MyDrive/brennar5_imgs'\n",
        "    # output = '/content/converted_5_output.csv'\n",
        "    output = '/content/brennar5.csv'\n",
        "    # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "    # label_file = '/content/test_labels.txt'\n",
        "    # labels = None\n",
        "    # with open(label_file,\"+r\") as f:\n",
        "    #   labelList = f.readlines()\n",
        "    #   labels = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "\n",
        "\n",
        "# Pi Addresses\n",
        "    # model_name = '/users/ugrad/brennar5/captcha_detection/converted_test.tflite'\n",
        "    # captcha_dir = '/users/ugrad/brennar5/captcha_detection/testers_4'\n",
        "    # output = '/users/ugrad/brennar5/captcha_detection/converted_4_output.csv'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    # captcha_symbols = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with open(output, 'w') as output_file:\n",
        "        \n",
        "        tf_interpreter = tflite.Interpreter(model_name)\n",
        "        tf_interpreter.allocate_tensors()\n",
        "        input_tf = tf_interpreter.get_input_details()\n",
        "        output_tf = tf_interpreter.get_output_details()\n",
        "        # print(input_tf)\n",
        "        # print(output_tf)\n",
        "\n",
        "        files = os.listdir(captcha_dir)\n",
        "        files = sorted(files)\n",
        "\n",
        "        for x in files:\n",
        "            # Load & Preprocess Image - Currently to work with test\n",
        "            raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "            image = pyPreprocess(raw_data)\n",
        "            \n",
        "            tf_interpreter.set_tensor(input_tf[0]['index'],image)\n",
        "            tf_interpreter.invoke()\n",
        "            prediction = []\n",
        "            for output_node in output_tf:\n",
        "                prediction.append(tf_interpreter.get_tensor(output_node['index']))\n",
        "            prediction = np.reshape(prediction,(len(output_tf),-1))\n",
        "            predictedAnswer = decode(captcha_symbols, prediction)\n",
        "            predictedAnswer.strip()\n",
        "            predictedAnswer = predictedAnswer.replace(\" \", \"\")\n",
        "            # predictedAnswer = predictedAnswer.replace(\"_\", \"\")\n",
        "            output_file.write(x + \",\" + predictedAnswer + \"\\n\")\n",
        "            \n",
        "            # answer = labels.get(x)\n",
        "            # print('Classified ' + answer + '///' + predictedAnswer)\n",
        "\n",
        "            answer = x[:-4]\n",
        "            # answer = labels.get(x)\n",
        "            if (answer == predictedAnswer) :\n",
        "                correct = correct + 1\n",
        "                print('^ CORRECT ^')\n",
        "            else :\n",
        "                incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}