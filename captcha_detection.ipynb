{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captcha_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthbrennankk/scalable_group_project/blob/master/captcha_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP7l_S8Bax1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bb68f008-5a00-48da-b099-4fc48b91eabd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi30LY3zCvY3"
      },
      "source": [
        "!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "!pip install captcha\n",
        "!pip install stsci.ndimage"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hrYMIRvCwRN"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import scipy.ndimage\n",
        "import random\n",
        "import captcha.image\n",
        "\n",
        "from PIL import Image\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import shutil\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDkPlwlhV5e"
      },
      "source": [
        "captcha_symbols = \"ABCDeFghijkMnPQRSTUVWXxYZz0123456789#/\\[]:><%{}-+\" #19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfxS5RzBerO"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "\n",
        "def preprocess(raw_data) :\n",
        "    return smallPreprocess(raw_data)\n",
        "\n",
        "def lose_circles(i, cs):\n",
        "    cs = cs[0]\n",
        "    for c in cs:\n",
        "        i = cv2.circle(i, (round(c[0]),round(c[1])), radius=round(c[2]), color=255, thickness=1)\n",
        "    return i\n",
        "\n",
        "def circles(i):\n",
        "    cs = cv2.HoughCircles(i, method=cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=5, minRadius=0, maxRadius=2)\n",
        "    if cs is not None:\n",
        "        i = lose_circles(i, cs)\n",
        "    return i\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2RGB)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def pyPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2RGB)\n",
        "    image = np.array(img, dtype=np.float32) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def bigPreprocess(raw_data) :\n",
        "    #   Back to Black\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "    # First Pass\n",
        "    img = ~img  # invert\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # weaken noise\n",
        "    img = ~img  # re-invert\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # target lines\n",
        "    img = scipy.ndimage.median_filter(img, (1, 3))  # target circles\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)\n",
        "    img = scipy.ndimage.median_filter(img, (3, 3))  # target weak noise\n",
        "    img = circles(img)  # Use Hough Transform on remaining circles\n",
        "    # Last Pass\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # actually performs erosion\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # finally completely remove any extra noise that remains\n",
        "    img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=2)  # dilate image to make it look like the original\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    #Edge Detection\n",
        "    # img = cv2.Canny(img, 100, 200)\n",
        "    # Back to Colour\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Format - (different for pi)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    return image.reshape([-1, c, h, w])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct97WoykCWlG"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "def generate(count, output_dir, outputFile):\n",
        "    width = 128\n",
        "    height = 64\n",
        "    captcha_symbols_g = captcha_symbols\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols_g + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols_g) for j in range(caplength)])\n",
        "\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = np.array(captcha_generator.generate_image(random_str))\n",
        "        cv2.imwrite(image_path, image)\n",
        "\n",
        "        with open(outputFile,'+a') as f:\n",
        "            f.write(img_name + \",\" + random_str + \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCsAJnz2-7Jv"
      },
      "source": [
        "# Calls to Generate  \n",
        "generate(192000, '/content/train_set', '/content/train_labels.txt') # Train Set\n",
        "generate(19200, '/content/val_set', '/content/val_labels.txt')  # Validation Set\n",
        "generate(100, '/content/test_set', '/content/test_labels.txt')  # Test Set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANHumMjC0l6"
      },
      "source": [
        "# Train\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Build a Keras model given some parameters\n",
        "def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):\n",
        "  input_tensor = keras.Input(input_shape)\n",
        "  x = input_tensor\n",
        "  for i, module_length in enumerate([module_size] * model_depth):\n",
        "      for j in range(module_length):\n",
        "          x = keras.layers.Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "          x = keras.layers.BatchNormalization()(x)\n",
        "          x = keras.layers.Activation('relu')(x)\n",
        "      x = keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = [keras.layers.Dense(captcha_num_symbols, activation='softmax', name='char_%d'%(i+1))(x) for i in range(captcha_length)]\n",
        "  model = keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "  return model\n",
        "\n",
        "# A Sequence represents a dataset for training in Keras\n",
        "# In this case, we have a folder full of images\n",
        "# Elements of a Sequence are *batches* of images, of some size batch_size\n",
        "class ImageSequence(keras.utils.Sequence):\n",
        "    def __init__(self, directory_name, label_file, batch_size, captcha_length, captcha_symbols, captcha_width, captcha_height):\n",
        "        self.directory_name = directory_name\n",
        "        self.batch_size = batch_size\n",
        "        self.captcha_length = captcha_length\n",
        "        self.captcha_symbols = captcha_symbols\n",
        "        self.captcha_width = captcha_width\n",
        "        self.captcha_height = captcha_height\n",
        "        with open(label_file,\"+r\") as f:\n",
        "          labelList = f.readlines()\n",
        "          self.labels = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "        file_list = os.listdir(self.directory_name)\n",
        "        self.files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "        self.used_files = []\n",
        "        self.count = len(file_list)\n",
        "        # print('dir name ' + self.directory_name)\n",
        "        # print(self.count)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.count / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = np.zeros((self.batch_size, self.captcha_height, self.captcha_width, 3), dtype=np.float32)\n",
        "        y = [np.zeros((self.batch_size, len(self.captcha_symbols)), dtype=np.uint8) for i in range(self.captcha_length)]\n",
        "\n",
        "        for i in range(min(self.batch_size, len(self.files))):\n",
        "            random_image_name = random.choice(list(self.labels.keys()))\n",
        "            random_image_label = self.labels[random_image_name]\n",
        "            random_image_file = self.files[random_image_name[:-4]]\n",
        "\n",
        "            # We've used this image now, so we can't repeat it in this iteration\n",
        "            self.used_files.append(self.files.pop(random_image_name[:-4]))\n",
        "            self.labels.pop(random_image_name)\n",
        "\n",
        "            # We have to scale the input pixel values to the range [0, 1] for\n",
        "            # Keras so we divide by 255 since the image is 8-bit RGB\n",
        "            raw_data = cv2.imread(os.path.join(self.directory_name, random_image_file))\n",
        "            processed_data = preprocess(raw_data)\n",
        "            X[i] = processed_data\n",
        "\n",
        "            if len(random_image_label) < self.captcha_length :\n",
        "              balance = self.captcha_length - len(random_image_label)\n",
        "              for x in range(0, balance) :\n",
        "                random_image_label = random_image_label + ' '\n",
        "            \n",
        "            for j, ch in enumerate(random_image_label):\n",
        "                y[j][i, :] = 0\n",
        "                y[j][i, self.captcha_symbols.find(ch)] = 1\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def train():\n",
        "    # Inputs\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6 \n",
        "    batch_size = 32\n",
        "    epochs = 2 #8\n",
        "    train_dataset = '/content/train_set/'\n",
        "    train_labels_file = '/content/train_labels.txt'\n",
        "    validate_dataset = '/content/val_set/'\n",
        "    val_labels_file = '/content/val_labels.txt'\n",
        "    output_model_name = '/content/model_19_e7'\n",
        "    input_model = '/content/model_19_e5' \n",
        "    captcha_symbols_t = captcha_symbols + ' '\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = create_model(length, len(captcha_symbols_t), (height, width, 3))\n",
        "        if input_model is not None:\n",
        "            model.load_weights(input_model+'.h5')\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                      metrics=['accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        training_data = ImageSequence(train_dataset, train_labels_file, batch_size, length, captcha_symbols_t, width, height)\n",
        "        validation_data = ImageSequence(validate_dataset, val_labels_file, batch_size, length, captcha_symbols_t, width, height)\n",
        "\n",
        "        callbacks = [keras.callbacks.EarlyStopping(patience=3),\n",
        "                      # keras.callbacks.CSVLogger('log.csv'),\n",
        "                      keras.callbacks.ModelCheckpoint(output_model_name+'.h5', save_best_only=False)]\n",
        "\n",
        "        # Save the model architecture to JSON\n",
        "        with open(output_model_name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(model.to_json())\n",
        "\n",
        "        try:\n",
        "            model.fit_generator(generator=training_data,\n",
        "                                validation_data=validation_data,\n",
        "                                epochs=epochs,\n",
        "                                callbacks=callbacks,\n",
        "                                use_multiprocessing=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyboardInterrupt caught, saving current weights as ' + output_model_name+'_resume.h5')\n",
        "            model.save_weights(output_model_name+'_resume.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IcKsswbLGJK"
      },
      "source": [
        "#   Classify\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    model_name = '/content/model_19_e7'\n",
        "    captcha_dir = '/content/test_set/'\n",
        "    label_file = '/content/test_labels.txt'\n",
        "    output = '/content/output.csv'\n",
        "\n",
        "    labels = None\n",
        "    with open(label_file,\"+r\") as f:\n",
        "      labelList = f.readlines()\n",
        "      labels = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "\n",
        "    captcha_symbols_c = captcha_symbols + ' '\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols_c + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        with open(output, 'w') as output_file:\n",
        "            json_file = open(model_name+'.json', 'r')\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            model = keras.models.model_from_json(loaded_model_json)\n",
        "            model.load_weights(model_name+'.h5')\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                          metrics=['accuracy'])\n",
        "            \n",
        "            for x in os.listdir(captcha_dir):\n",
        "                # load image and preprocess it\n",
        "                raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "                image = preprocess(raw_data)\n",
        "\n",
        "                prediction = model.predict(image)\n",
        "                predictedAnswer = decode(captcha_symbols_c, prediction)\n",
        "                output_file.write(x + \", \" + predictedAnswer + \"\\n\")\n",
        "                predictedAnswer = predictedAnswer.replace(\" \", \"\")\n",
        "\n",
        "                answer = labels.get(x)\n",
        "                print('Classified ' + x + ' ' + answer + '///' + predictedAnswer)\n",
        "                if (answer == predictedAnswer) :\n",
        "                    correct = correct + 1\n",
        "                    print('^ CORRECT ^')\n",
        "                else :\n",
        "                    incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVVklkiDGy_"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Converter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def main(model_name):\n",
        "    with open(f'/content/{model_name}.json') as f:\n",
        "        model = f.read()\n",
        "    model = keras.models.model_from_json(model)\n",
        "    model.load_weights(f'/content/{model_name}.h5')\n",
        "    cvt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite = cvt.convert()\n",
        "    with open(f'/content/converted_{model_name}.tflite', 'wb') as f:\n",
        "        f.write(tflite)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = 'model_19_e7'\n",
        "    main(model_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D5HK4YIc-t"
      },
      "source": [
        "# Classify - Lite\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=1)\n",
        "    #y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    \n",
        "    model_name = '/content/converted_model_19_e7.tflite'\n",
        "    captcha_dir = '/content/drive/MyDrive/Ruth/brennar5_imgs'\n",
        "    output = '/content/brennar5_m17_e6_a11.csv'\n",
        "    captcha_symbols_c = captcha_symbols + ' '\n",
        "\n",
        "# Pi Addresses\n",
        "    # model_name = '/users/ugrad/brennar5/captcha_detection/converted_test.tflite'\n",
        "    # captcha_dir = '/users/ugrad/brennar5/captcha_detection/testers_4'\n",
        "    # output = '/users/ugrad/brennar5/captcha_detection/converted_4_output.csv'\n",
        "\n",
        "    count = 0\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols_c + \"}\")\n",
        "    with open(output, 'w') as output_file:\n",
        "        \n",
        "        tf_interpreter = tflite.Interpreter(model_name)\n",
        "        tf_interpreter.allocate_tensors()\n",
        "        input_tf = tf_interpreter.get_input_details()\n",
        "        output_tf = tf_interpreter.get_output_details()\n",
        "        files = os.listdir(captcha_dir)\n",
        "        files = sorted(files)\n",
        "\n",
        "        for x in files:\n",
        "            # Load & Preprocess Image - Currently to work with test\n",
        "            raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "            image = pyPreprocess(raw_data)\n",
        "            \n",
        "            tf_interpreter.set_tensor(input_tf[0]['index'],image)\n",
        "            tf_interpreter.invoke()\n",
        "            prediction = []\n",
        "            for output_node in output_tf:\n",
        "                prediction.append(tf_interpreter.get_tensor(output_node['index']))\n",
        "            prediction = np.reshape(prediction,(len(output_tf),-1))\n",
        "            predictedAnswer = decode(captcha_symbols_c, prediction)\n",
        "            predictedAnswer.strip()\n",
        "            predictedAnswer = predictedAnswer.replace(\" \", \"\")\n",
        "            output_file.write(x + \",\" + predictedAnswer + \"\\n\")\n",
        "\n",
        "            answer = x[:-4]            \n",
        "            print('Classified (count ' + str(count) + ') ' + answer + '///' + predictedAnswer)\n",
        "            count = count + 1\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}