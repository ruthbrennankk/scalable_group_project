{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "captcha_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthbrennankk/scalable_group_project/blob/master/captcha_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP7l_S8Bax1"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import scipy.ndimage\n",
        "import random\n",
        "import captcha.image\n",
        "\n",
        "from PIL import Image\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import shutil\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi30LY3zCvY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c29abb5-5e7d-4f45-d41d-fb36d7b8058b"
      },
      "source": [
        "!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "!pip install captcha\n",
        "!pip install stsci.ndimage"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://google-coral.github.io/py-repo/\n",
            "Collecting tflite_runtime\n",
            "  Downloading https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 29.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n",
            "Installing collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.5.0.post1\n",
            "Collecting captcha\n",
            "  Downloading captcha-0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from captcha) (7.1.2)\n",
            "Installing collected packages: captcha\n",
            "Successfully installed captcha-0.3\n",
            "Collecting stsci.ndimage\n",
            "  Downloading stsci.ndimage-0.10.3.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 11.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from stsci.ndimage) (1.19.5)\n",
            "Building wheels for collected packages: stsci.ndimage\n",
            "  Building wheel for stsci.ndimage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stsci.ndimage: filename=stsci.ndimage-0.10.3-cp37-cp37m-linux_x86_64.whl size=235563 sha256=fd0c4e04c5e13caff43fd463d5036b8c56ccbaf03b2548cdbe9b4bbcd70a9c8d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f6/da/e57766b5a06db608d4b613aa9124957d95b072367bab3aafef\n",
            "Successfully built stsci.ndimage\n",
            "Installing collected packages: stsci.ndimage\n",
            "Successfully installed stsci.ndimage-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hrYMIRvCwRN"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDkPlwlhV5e"
      },
      "source": [
        "captcha_symbols=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#[]+:></%{}\" # I didn't see it in mine but potentially '\\'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfxS5RzBerO"
      },
      "source": [
        "# Preprocess\n",
        "def preprocess(raw_data) :\n",
        "    return bigPreprocess(raw_data)\n",
        "\n",
        "def erase_circles(img, circles):\n",
        "    circles = circles[0]  # hough circles returns a nested list for some reason\n",
        "    for circle in circles:\n",
        "        center = (round(circle[0]),round(circle[1]))\n",
        "        img = cv2.circle(img, center, radius=round(circle[2]), color=255, thickness=1)  # erase circle by making it white (to match the image background)\n",
        "    return img\n",
        "\n",
        "def detect_and_remove_circles(img):\n",
        "    hough_circle_locations = cv2.HoughCircles(img, method=cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=5, minRadius=0, maxRadius=2)\n",
        "    if hough_circle_locations is not None:\n",
        "        img = erase_circles(img, hough_circle_locations)\n",
        "    return img\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def bigPreprocess(raw_data) :\n",
        "    #   Back to Black\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "    # run some basic tests to get rid of easy-to-remove noise -- first pass\n",
        "    img = ~img  # white letters, black background\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # weaken circle noise and line noise\n",
        "    img = ~img  # black letters, white background\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # remove line noise\n",
        "    img = scipy.ndimage.median_filter(img, (1, 3))  # weaken circle noise\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = scipy.ndimage.median_filter(img, (3, 3))  # remove any final 'weak' noise that might be present (line or circle)\n",
        "    # detect any remaining circle noise\n",
        "    img = detect_and_remove_circles(img)  # after dilation, if concrete circles exist, use hough transform to remove them\n",
        "    # eradicate any final noise that wasn't removed previously -- second pass\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # actually performs erosion\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # finally completely remove any extra noise that remains\n",
        "    img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=2)  # dilate image to make it look like the original\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    #Edge Detection\n",
        "    # img = cv2.Canny(img, 100, 200)\n",
        "    # Back to Colour\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Format - (different for pi)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    return image.reshape([-1, c, h, w])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct97WoykCWlG"
      },
      "source": [
        "# Train\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Build a Keras model given some parameters\n",
        "def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):\n",
        "  input_tensor = keras.Input(input_shape)\n",
        "  x = input_tensor\n",
        "  for i, module_length in enumerate([module_size] * model_depth):\n",
        "      for j in range(module_length):\n",
        "          x = keras.layers.Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "          x = keras.layers.BatchNormalization()(x)\n",
        "          x = keras.layers.Activation('relu')(x)\n",
        "      x = keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = [keras.layers.Dense(captcha_num_symbols, activation='softmax', name='char_%d'%(i+1))(x) for i in range(captcha_length)]\n",
        "  model = keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "  return model\n",
        "\n",
        "# A Sequence represents a dataset for training in Keras\n",
        "# In this case, we have a folder full of images\n",
        "# Elements of a Sequence are *batches* of images, of some size batch_size\n",
        "class ImageSequence(keras.utils.Sequence):\n",
        "    def __init__(self, directory_name, batch_size, captcha_length, captcha_symbols, captcha_width, captcha_height):\n",
        "        self.directory_name = directory_name\n",
        "        self.batch_size = batch_size\n",
        "        self.captcha_length = captcha_length\n",
        "        self.captcha_symbols = captcha_symbols\n",
        "        self.captcha_width = captcha_width\n",
        "        self.captcha_height = captcha_height\n",
        "\n",
        "        file_list = os.listdir(self.directory_name)\n",
        "        self.files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "        self.used_files = []\n",
        "        self.count = len(file_list)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.count / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = np.zeros((self.batch_size, self.captcha_height, self.captcha_width, 3), dtype=np.float32)\n",
        "        y = [np.zeros((self.batch_size, len(self.captcha_symbols)), dtype=np.uint8) for i in range(self.captcha_length)]\n",
        "\n",
        "        for i in range(min(self.batch_size, len(self.files))):\n",
        "            random_image_label = random.choice(list(self.files.keys()))\n",
        "            random_image_file = self.files[random_image_label]\n",
        "\n",
        "            # We've used this image now, so we can't repeat it in this iteration\n",
        "            self.used_files.append(self.files.pop(random_image_label))\n",
        "\n",
        "            # We have to scale the input pixel values to the range [0, 1] for\n",
        "            # Keras so we divide by 255 since the image is 8-bit RGB\n",
        "            raw_data = cv2.imread(os.path.join(self.directory_name, random_image_file))\n",
        "            processed_data = preprocess(raw_data)\n",
        "            X[i] = processed_data\n",
        "\n",
        "            random_image_label = random_image_label.split('_')[0]\n",
        "\n",
        "            for j, ch in enumerate(random_image_label):\n",
        "                y[j][i, :] = 0\n",
        "                y[j][i, self.captcha_symbols.find(ch)] = 1\n",
        "\n",
        "        return X, y\n",
        "\n",
        "def main():\n",
        "    # inputs\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 5 \n",
        "    symbols = 'symbols.txt'\n",
        "    batch_size = 32\n",
        "    epochs = 5\n",
        "    train_dataset = 'train_data'\n",
        "    validate_dataset = 'val_data'\n",
        "    output_model_name = 'train_model_01'\n",
        "\n",
        "    # captcha_symbols = None\n",
        "    # with open(symbols) as symbols_file:\n",
        "    #     captcha_symbols = symbols_file.readline()\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = create_model(length, len(captcha_symbols), (height, width, 3))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        training_data = ImageSequence(train_dataset, batch_size, length, captcha_symbols, width, height)\n",
        "        validation_data = ImageSequence(validate_dataset, batch_size, length, captcha_symbols, width, height)\n",
        "\n",
        "        callbacks = [keras.callbacks.EarlyStopping(patience=3),\n",
        "                     # keras.callbacks.CSVLogger('log.csv'),\n",
        "                     keras.callbacks.ModelCheckpoint(output_model_name+'.h5', save_best_only=False)]\n",
        "\n",
        "        # Save the model architecture to JSON\n",
        "        with open(output_model_name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(model.to_json())\n",
        "\n",
        "        try:\n",
        "            model.fit_generator(generator=training_data,\n",
        "                                validation_data=validation_data,\n",
        "                                epochs=epochs,\n",
        "                                callbacks=callbacks,\n",
        "                                use_multiprocessing=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyboardInterrupt caught, saving current weights as ' + output_model_name+'_resume.h5')\n",
        "            model.save_weights(output_model_name+'_resume.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "6dI9wdAiCqTY",
        "outputId": "84ca6e6c-fb35-4d20-ec38-93b32df5fe74"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "def main():\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6\n",
        "    count = 1000 #100 #140800 #128000 - 40m\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/test_set' #test set\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/train_set' #training set\n",
        "    outputFile = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/training_lables'\n",
        "    output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set' #validation set\n",
        "    # Appedning symbol set with \\ and -\n",
        "    captcha_symbols=\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#[]+:></%{}\\-\" # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/symbols.txt'\n",
        "    # for x in range(0, 9):\n",
        "    #   captcha_symbols = captcha_symbols + ' '\n",
        "\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols) for j in range(caplength)])\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(args.output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(args.output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = numpy.array(captcha_generator.generate_image(random_str))\n",
        "        cv2.imwrite(image_path, image)\n",
        "        with open(outputFile,'+a') as f:\n",
        "            f.write(img_name + \", \" + random_str + \"\\n\")\n",
        "\n",
        "    # for i in range(count):\n",
        "    #     random_str = ''.join([random.choice(captcha_symbols) for j in range(length)])\n",
        "\n",
        "    #     filenames.append(random_str)\n",
        "\n",
        "    #     image_path = os.path.join(output_dir, str(index)+'.png')\n",
        "        \n",
        "    #     if os.path.exists(image_path):\n",
        "    #         version = 1\n",
        "    #         while os.path.exists(os.path.join(output_dir, str(index) + '_' + str(version) + '.png')):\n",
        "    #             version += 1\n",
        "    #         image_path = os.path.join(output_dir, str(index) + '_' + str(version) + '.png')\n",
        "\n",
        "    #     image = np.array(captcha_generator.generate_image(random_str))\n",
        "    #     cv2.imwrite(image_path, image)\n",
        "    #     index = index + 1\n",
        "\n",
        "    # pd.DataFrame(filenames).to_csv(\"/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set_names.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating captchas with symbol set {0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ#[]+:></%{}\\-}\n",
            "Creating output directory /content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7a70887b0a42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-6-7a70887b0a42>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcaplength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mrandom_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptcha_symbols\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaplength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'img_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNNcVwno0SAF",
        "outputId": "bfb422d6-7538-4c6a-de68-1bec44577e63"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANHumMjC0l6"
      },
      "source": [
        "# Move Files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# base = \"/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/\"\n",
        "base = '/content/'\n",
        "base_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/base'\n",
        "# files setup\n",
        "file_list = os.listdir(base_dir)\n",
        "files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "print('base len = ' + str(len(files)))\n",
        "\n",
        "# Train Setup\n",
        "train_dir = \"train_data\"\n",
        "# os.mkdir(base + train_dir)\n",
        "\n",
        "# Val Setup\n",
        "val_dir = \"val_data\"\n",
        "val_size = 12800\n",
        "# os.mkdir(base + val_dir)\n",
        "\n",
        "#   Addressing Files\n",
        "baseTake = base_dir\n",
        "# baseTake = base + base_dir\n",
        "basePutTrain = base + train_dir\n",
        "basePutVal = base + val_dir\n",
        "\n",
        "#   Val Takes\n",
        "for i in range(val_size):\n",
        "    random_image_label = random.choice(list(files.keys()))\n",
        "    random_image_label_file = random_image_label + '.png'\n",
        "    os.replace(os.path.join(baseTake, random_image_label_file), os.path.join(basePutVal, random_image_label_file))\n",
        "    files.pop(random_image_label)\n",
        "\n",
        "#   Train Takes\n",
        "for x in files:\n",
        "    # x = random.choice(list(files.keys()))\n",
        "    label = x + '.png'\n",
        "    os.replace(os.path.join(baseTake, label), os.path.join(basePutTrain, label))\n",
        "\n",
        "# Check Size - Test\n",
        "base_list = os.listdir(base_dir)\n",
        "print('base len = ' + str(len(base_list)))\n",
        "# Check Size - Train\n",
        "train_list = os.listdir(train_dir)\n",
        "print('train_data len = ' + str(len(train_list)))\n",
        "# Check Size - Val\n",
        "val_list = os.listdir(val_dir)\n",
        "print('val_list len = ' + str(len(val_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcKsswbLGJK",
        "outputId": "b1f9e51a-0d08-4a64-8dec-371f0b5fc785"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Converter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def main(model_name):\n",
        "    with open(f'/content/{model_name}.json') as f:\n",
        "        model = f.read()\n",
        "    model = keras.models.model_from_json(model)\n",
        "    model.load_weights(f'/content/{model_name}.h5')\n",
        "    cvt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite = cvt.convert()\n",
        "    with open(f'/content/drive/MyDrive/Year V/converted_{model_name}.tflite', 'wb') as f:\n",
        "        f.write(tflite)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = 'test'\n",
        "    main(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVVklkiDGy_"
      },
      "source": [
        "#   Classify\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    model_name = '/content/train_model_01'\n",
        "    captcha_dir = '/content/testers_5_lowercase'\n",
        "    output = '/content/output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        with open(output, 'w') as output_file:\n",
        "            json_file = open(model_name+'.json', 'r')\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            model = keras.models.model_from_json(loaded_model_json)\n",
        "            model.load_weights(model_name+'_resume.h5')\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            for x in os.listdir(captcha_dir):\n",
        "                # load image and preprocess it\n",
        "                raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "\n",
        "                #   Preprocess Image\n",
        "                image = preprocess(raw_data)\n",
        "\n",
        "                prediction = model.predict(image)\n",
        "                predictedAnswer = decode(captcha_symbols, prediction)\n",
        "                output_file.write(x + \", \" + predictedAnswer + \"\\n\")\n",
        "\n",
        "                print('Classified ' + x + '///' + predictedAnswer)\n",
        "\n",
        "                answer = x[:-4]\n",
        "                if (answer == predictedAnswer) :\n",
        "                    correct = correct + 1\n",
        "                else :\n",
        "                    incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D5HK4YIc-t"
      },
      "source": [
        "# Classify - Lite\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=1)\n",
        "    #y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    \n",
        "    model_name = '/content/converted_test.tflite'\n",
        "    captcha_dir = '/content/testers_4_characters_no_lowercase'\n",
        "    output = '/content/converted_4_output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "# Pi Addresses\n",
        "    # model_name = '/users/ugrad/brennar5/captcha_detection/converted_test.tflite'\n",
        "    # captcha_dir = '/users/ugrad/brennar5/captcha_detection/testers_4'\n",
        "    # output = '/users/ugrad/brennar5/captcha_detection/converted_4_output.csv'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    # captcha_symbols = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with open(output, 'w') as output_file:\n",
        "        \n",
        "        tf_interpreter = tflite.Interpreter(model_name)\n",
        "        tf_interpreter.allocate_tensors()\n",
        "        input_tf = tf_interpreter.get_input_details()\n",
        "        output_tf = tf_interpreter.get_output_details()\n",
        "        # print(input_tf)\n",
        "        # print(output_tf)\n",
        "\n",
        "        files = os.listdir(captcha_dir)\n",
        "        files = sorted(files)\n",
        "\n",
        "        for x in files:\n",
        "            # Load & Preprocess Image - Currently to work with test\n",
        "            raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "            rgb_data = cv2.cvtColor(raw_data, cv2.COLOR_BGR2RGB)\n",
        "            image = np.array(rgb_data, dtype=np.float32) / 255.0\n",
        "            (c, h, w) = image.shape\n",
        "            image = image.reshape([-1, c, h, w])\n",
        "            \n",
        "            tf_interpreter.set_tensor(input_tf[0]['index'],image)\n",
        "            tf_interpreter.invoke()\n",
        "            prediction = []\n",
        "            for output_node in output_tf:\n",
        "                prediction.append(tf_interpreter.get_tensor(output_node['index']))\n",
        "            prediction = np.reshape(prediction,(len(output_tf),-1))\n",
        "            decoded_symbol = decode(captcha_symbols, prediction)\n",
        "            output_file.write(x + \",\" + decoded_symbol + \"\\n\")\n",
        "            \n",
        "            print('Classified ' + x + '///' + decoded_symbol)\n",
        "\n",
        "            answer = x[:-4]\n",
        "            if (answer == decoded_symbol) :\n",
        "                correct = correct + 1\n",
        "            else :\n",
        "                incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}