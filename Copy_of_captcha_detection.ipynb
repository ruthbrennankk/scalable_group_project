{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of captcha_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthbrennankk/scalable_group_project/blob/master/Copy_of_captcha_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP7l_S8Bax1"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import scipy.ndimage\n",
        "import random\n",
        "import captcha.image\n",
        "\n",
        "from PIL import Image\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import shutil\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi30LY3zCvY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2db50dc6-754b-4cc1-8f99-7786c0339993"
      },
      "source": [
        "!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "!pip install captcha\n",
        "!pip install stsci.ndimage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://google-coral.github.io/py-repo/\n",
            "Collecting tflite_runtime\n",
            "  Downloading https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 18.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n",
            "Installing collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.5.0.post1\n",
            "Collecting captcha\n",
            "  Downloading captcha-0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from captcha) (7.1.2)\n",
            "Installing collected packages: captcha\n",
            "Successfully installed captcha-0.3\n",
            "Collecting stsci.ndimage\n",
            "  Downloading stsci.ndimage-0.10.3.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from stsci.ndimage) (1.19.5)\n",
            "Building wheels for collected packages: stsci.ndimage\n",
            "  Building wheel for stsci.ndimage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stsci.ndimage: filename=stsci.ndimage-0.10.3-cp37-cp37m-linux_x86_64.whl size=235608 sha256=411e8debff3158be568e0c8380f404d358796f860131f4b0d71b964ba57b3365\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f6/da/e57766b5a06db608d4b613aa9124957d95b072367bab3aafef\n",
            "Successfully built stsci.ndimage\n",
            "Installing collected packages: stsci.ndimage\n",
            "Successfully installed stsci.ndimage-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hrYMIRvCwRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5643e31c-d2b6-44d8-dd45-2c4f372321d5"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDkPlwlhV5e"
      },
      "source": [
        "captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\- \" # I didn't see it in mine but potentially '\\'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfxS5RzBerO"
      },
      "source": [
        "# Preprocess\n",
        "def preprocess(raw_data) :\n",
        "    return bigPreprocess(raw_data)\n",
        "\n",
        "def erase_circles(img, circles):\n",
        "    circles = circles[0]  # hough circles returns a nested list for some reason\n",
        "    for circle in circles:\n",
        "        center = (round(circle[0]),round(circle[1]))\n",
        "        img = cv2.circle(img, center, radius=round(circle[2]), color=255, thickness=1)  # erase circle by making it white (to match the image background)\n",
        "    return img\n",
        "\n",
        "def detect_and_remove_circles(img):\n",
        "    hough_circle_locations = cv2.HoughCircles(img, method=cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=5, minRadius=0, maxRadius=2)\n",
        "    if hough_circle_locations is not None:\n",
        "        img = erase_circles(img, hough_circle_locations)\n",
        "    return img\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def bigPreprocess(raw_data) :\n",
        "    #   Back to Black\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "    # run some basic tests to get rid of easy-to-remove noise -- first pass\n",
        "    img = ~img  # white letters, black background\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # weaken circle noise and line noise\n",
        "    img = ~img  # black letters, white background\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # remove line noise\n",
        "    img = scipy.ndimage.median_filter(img, (1, 3))  # weaken circle noise\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = scipy.ndimage.median_filter(img, (3, 3))  # remove any final 'weak' noise that might be present (line or circle)\n",
        "    # detect any remaining circle noise\n",
        "    img = detect_and_remove_circles(img)  # after dilation, if concrete circles exist, use hough transform to remove them\n",
        "    # eradicate any final noise that wasn't removed previously -- second pass\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # actually performs erosion\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # finally completely remove any extra noise that remains\n",
        "    img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=2)  # dilate image to make it look like the original\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    #Edge Detection\n",
        "    # img = cv2.Canny(img, 100, 200)\n",
        "    # Back to Colour\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Format - (different for pi)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    return image.reshape([-1, c, h, w])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct97WoykCWlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681f422d-24eb-4adc-c23c-85eeef1f2947"
      },
      "source": [
        "# Train\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Build a Keras model given some parameters\n",
        "def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):\n",
        "  input_tensor = keras.Input(input_shape)\n",
        "  x = input_tensor\n",
        "  for i, module_length in enumerate([module_size] * model_depth): \n",
        "      for j in range(module_length):\n",
        "          x = keras.layers.Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "          x = keras.layers.BatchNormalization()(x)\n",
        "          x = keras.layers.Activation('relu')(x)\n",
        "      x = keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = [keras.layers.Dense(captcha_num_symbols, activation='softmax', name='char_%d'%(i+1))(x) for i in range(captcha_length)]\n",
        "  model = keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "  return model\n",
        "\n",
        "# A Sequence represents a dataset for training in Keras\n",
        "# In this case, we have a folder full of images\n",
        "# Elements of a Sequence are *batches* of images, of some size batch_size\n",
        "class ImageSequence(keras.utils.Sequence):\n",
        "    def __init__(self, directory_name, batch_size, label_file, captcha_symbols, captcha_width, captcha_height):\n",
        "        self.directory_name = directory_name\n",
        "        self.batch_size = batch_size\n",
        "        self.captcha_length = 6\n",
        "        self.captcha_symbols = captcha_symbols\n",
        "        self.captcha_width = captcha_width\n",
        "        self.captcha_height = captcha_height\n",
        "        self.label_file = label_file\n",
        "        file_list = os.listdir(self.directory_name)\n",
        "        with open(self.label_file,\"+r\") as f:\n",
        "          labelList = f.readlines()\n",
        "          self.files = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(),labelList)))\n",
        "        self.used_files = []\n",
        "        self.count = len(file_list)\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.count / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = np.zeros((self.batch_size, self.captcha_height, self.captcha_width, 3), dtype=np.float32)\n",
        "        y = [np.zeros((self.batch_size, len(self.captcha_symbols)), dtype=np.uint8) for i in range(self.captcha_length)]\n",
        "\n",
        "        for i in range(min(self.batch_size, len(self.files))):\n",
        "            random_image_file = random.choice(list(self.files.keys()))\n",
        "            random_image_label = self.files[random_image_file]\n",
        "            # We've used this image now, so we can't repeat it in this iteration\n",
        "            #self.used_files.append(self.files.pop(random_image_label))\n",
        "\n",
        "            # We have to scale the input pixel values to the range [0, 1] for\n",
        "            # Keras so we divide by 255 since the image is 8-bit RGB\n",
        "            raw_data = cv2.imread(os.path.join(self.directory_name, random_image_file))\n",
        "            processed_data = preprocess(raw_data)\n",
        "            X[i] = processed_data\n",
        "            random_image_label = random_image_label.split('_')[0]\n",
        "            for j, ch in enumerate(random_image_label):\n",
        "                y[j][i, :] = 0\n",
        "                y[j][i, self.captcha_symbols.find(ch)] = 1\n",
        "        return X, y\n",
        "\n",
        "def main():\n",
        "    # inputs\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6 \n",
        "    symbols = 'symbols.txt'\n",
        "    batch_size = 32\n",
        "    epochs = 9\n",
        "    output_model_name = 'train_model_01'\n",
        "    validate_outputFile = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/validation_lables.txt'\n",
        "    validate_dataset = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/validation_data/'\n",
        "    train_dataset = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/training_data/'\n",
        "    train_outputFile = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/training_lables.txt'\n",
        "    captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\- \"\n",
        "    # captcha_symbols = None\n",
        "    # with open(symbols) as symbols_file:\n",
        "    #     captcha_symbols = symbols_file.readline()\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = create_model(length, len(captcha_symbols), (height, width, 3))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        training_data = ImageSequence(train_dataset, batch_size,train_outputFile, captcha_symbols, width, height)\n",
        "        validation_data = ImageSequence(validate_dataset, batch_size, validate_outputFile, captcha_symbols, width, height)\n",
        "\n",
        "        callbacks = [keras.callbacks.EarlyStopping(patience=3),\n",
        "                     # keras.callbacks.CSVLogger('log.csv'),\n",
        "                     keras.callbacks.ModelCheckpoint(output_model_name+'.h5', save_best_only=False)]\n",
        "\n",
        "        # Save the model architecture to JSON\n",
        "        with open(output_model_name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(model.to_json())\n",
        "\n",
        "        try:\n",
        "            model.fit_generator(generator=training_data,\n",
        "                                validation_data=validation_data,\n",
        "                                epochs=epochs,\n",
        "                                callbacks=callbacks,\n",
        "                                use_multiprocessing=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyboardInterrupt caught, saving current weights as ' + output_model_name+'_resume.h5')\n",
        "            model.save_weights(output_model_name+'_resume.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 64, 128, 3)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 64, 128, 32)  896         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 64, 128, 32)  128         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 64, 128, 32)  0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 64, 128, 32)  9248        activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 64, 128, 32)  128         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 64, 128, 32)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling2D) (None, 32, 64, 32)   0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 32, 64, 64)   18496       max_pooling2d_15[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 32, 64, 64)   256         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 32, 64, 64)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 32, 64, 64)   36928       activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 32, 64, 64)   256         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 32, 64, 64)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling2D) (None, 16, 32, 64)   0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 16, 32, 128)  73856       max_pooling2d_16[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 16, 32, 128)  512         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 16, 32, 128)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 16, 32, 128)  147584      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 16, 32, 128)  512         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 16, 32, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling2D) (None, 8, 16, 128)   0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 16, 256)   295168      max_pooling2d_17[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 16, 256)   1024        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 16, 256)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 16, 256)   590080      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 16, 256)   1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 16, 256)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling2D) (None, 4, 8, 256)    0           activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 4, 8, 256)    590080      max_pooling2d_18[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 4, 8, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 4, 8, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 4, 8, 256)    590080      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 4, 8, 256)    1024        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 4, 8, 256)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling2D) (None, 2, 4, 256)    0           activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 2048)         0           max_pooling2d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "char_1 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_2 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_3 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_4 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_5 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_6 (Dense)                  (None, 62)           127038      flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,120,532\n",
            "Trainable params: 3,117,588\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "3125/3125 [==============================] - 1069s 341ms/step - loss: 88.3732 - char_1_loss: 33.6370 - char_2_loss: 24.1078 - char_3_loss: 15.6401 - char_4_loss: 9.0798 - char_5_loss: 4.3303 - char_6_loss: 1.5782 - char_1_accuracy: 0.0179 - char_2_accuracy: 0.0166 - char_3_accuracy: 0.0161 - char_4_accuracy: 0.0172 - char_5_accuracy: 0.0204 - char_6_accuracy: 0.0114 - val_loss: 128.4402 - val_char_1_loss: 48.2797 - val_char_2_loss: 32.4838 - val_char_3_loss: 25.7389 - val_char_4_loss: 13.6479 - val_char_5_loss: 6.0437 - val_char_6_loss: 2.2461 - val_char_1_accuracy: 0.0191 - val_char_2_accuracy: 0.0112 - val_char_3_accuracy: 0.0100 - val_char_4_accuracy: 0.0097 - val_char_5_accuracy: 0.0072 - val_char_6_accuracy: 0.0033\n",
            "Epoch 2/9\n",
            "3125/3125 [==============================] - 1055s 337ms/step - loss: 242.5716 - char_1_loss: 89.0341 - char_2_loss: 66.9703 - char_3_loss: 44.4241 - char_4_loss: 26.0845 - char_5_loss: 12.0649 - char_6_loss: 3.9937 - char_1_accuracy: 0.0164 - char_2_accuracy: 0.0158 - char_3_accuracy: 0.0166 - char_4_accuracy: 0.0160 - char_5_accuracy: 0.0171 - char_6_accuracy: 0.0154 - val_loss: 244.5244 - val_char_1_loss: 84.3180 - val_char_2_loss: 59.6956 - val_char_3_loss: 52.3268 - val_char_4_loss: 27.8546 - val_char_5_loss: 13.9954 - val_char_6_loss: 6.3340 - val_char_1_accuracy: 0.0200 - val_char_2_accuracy: 0.0148 - val_char_3_accuracy: 0.0085 - val_char_4_accuracy: 0.0101 - val_char_5_accuracy: 0.0061 - val_char_6_accuracy: 0.0036\n",
            "Epoch 3/9\n",
            "3125/3125 [==============================] - 1095s 350ms/step - loss: 379.1108 - char_1_loss: 137.8209 - char_2_loss: 103.8571 - char_3_loss: 70.1605 - char_4_loss: 41.5987 - char_5_loss: 19.4500 - char_6_loss: 6.2239 - char_1_accuracy: 0.0165 - char_2_accuracy: 0.0158 - char_3_accuracy: 0.0156 - char_4_accuracy: 0.0153 - char_5_accuracy: 0.0159 - char_6_accuracy: 0.0157 - val_loss: 417.8643 - val_char_1_loss: 144.7371 - val_char_2_loss: 114.1915 - val_char_3_loss: 78.2502 - val_char_4_loss: 50.1678 - val_char_5_loss: 23.2587 - val_char_6_loss: 7.2591 - val_char_1_accuracy: 0.0207 - val_char_2_accuracy: 0.0153 - val_char_3_accuracy: 0.0109 - val_char_4_accuracy: 0.0077 - val_char_5_accuracy: 0.0059 - val_char_6_accuracy: 0.0038\n",
            "Epoch 4/9\n",
            "3125/3125 [==============================] - 1113s 356ms/step - loss: 505.4096 - char_1_loss: 183.5566 - char_2_loss: 138.4279 - char_3_loss: 93.4859 - char_4_loss: 55.4594 - char_5_loss: 26.2939 - char_6_loss: 8.1860 - char_1_accuracy: 0.0172 - char_2_accuracy: 0.0162 - char_3_accuracy: 0.0162 - char_4_accuracy: 0.0159 - char_5_accuracy: 0.0167 - char_6_accuracy: 0.0161 - val_loss: 464.0144 - val_char_1_loss: 175.2481 - val_char_2_loss: 143.0967 - val_char_3_loss: 76.2868 - val_char_4_loss: 39.1725 - val_char_5_loss: 21.2860 - val_char_6_loss: 8.9243 - val_char_1_accuracy: 0.0169 - val_char_2_accuracy: 0.0124 - val_char_3_accuracy: 0.0121 - val_char_4_accuracy: 0.0097 - val_char_5_accuracy: 0.0063 - val_char_6_accuracy: 0.0014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j23CCojr1n4n",
        "outputId": "7b624e39-576a-4594-ff44-582fe5516e3c"
      },
      "source": [
        "# with open('/content/drive/My Drive/foo.txt', '+w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU9lkzH--UWW",
        "outputId": "dc434839-1b42-439e-fbd2-2487d4931339"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/MS/Sem1/Scalable\\ Computing/Project2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  training_data  training_lables.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dI9wdAiCqTY",
        "outputId": "c1e3190c-def6-43ca-8dc4-7fc85c2aa309"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "def main():\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6\n",
        "    count = 9999 #100 #140800 #128000 - 40m\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/test_set' #test set\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/train_set' #training set\n",
        "    outputFile = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/validation_lables.txt'\n",
        "    output_dir = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/validation_data/' #validation set\n",
        "    # Appedning symbol set with \\ and -\n",
        "    captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\- \" # I didn't see it in mine but potentially '\\'    # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/symbols.txt'\n",
        "    # for x in range(0, 9):\n",
        "    #   captcha_symbols = captcha_symbols + ' '\n",
        "\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols) for j in range(caplength)])\n",
        "        if(caplength<6):\n",
        "            random_char = list(random_str.ljust(6,\" \"))\n",
        "            random.shuffle(random_char)\n",
        "            random_str = ''.join(random_char)\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = np.array(captcha_generator.generate_image(random_str))\n",
        "        cv2.imwrite(image_path, image)\n",
        "        with open(outputFile,'a+') as f:\n",
        "            f.write(img_name + \",\" + random_str + \"\\n\")\n",
        "\n",
        "    # for i in range(count):\n",
        "    #     random_str = ''.join([random.choice(captcha_symbols) for j in range(length)])\n",
        "\n",
        "    #     filenames.append(random_str)\n",
        "\n",
        "    #     image_path = os.path.join(output_dir, str(index)+'.png')\n",
        "        \n",
        "    #     if os.path.exists(image_path):\n",
        "    #         version = 1\n",
        "    #         while os.path.exists(os.path.join(output_dir, str(index) + '_' + str(version) + '.png')):\n",
        "    #             version += 1\n",
        "    #         image_path = os.path.join(output_dir, str(index) + '_' + str(version) + '.png')\n",
        "\n",
        "    #     image = np.array(captcha_generator.generate_image(random_str))\n",
        "    #     cv2.imwrite(image_path, image)\n",
        "    #     index = index + 1\n",
        "\n",
        "    # pd.DataFrame(filenames).to_csv(\"/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set_names.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating captchas with symbol set {0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\- }\n",
            "Creating output directory /content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/validation_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANHumMjC0l6"
      },
      "source": [
        "#@title\n",
        "# Move Files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# base = \"/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/\"\n",
        "base = '/content/'\n",
        "base_dir = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/training_data'\n",
        "# files setup\n",
        "file_list = os.listdir(base_dir)\n",
        "files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "print('base len = ' + str(len(files)))\n",
        "\n",
        "# Train Setup\n",
        "train_dir = \"train_data\"\n",
        "# os.mkdir(base + train_dir)\n",
        "\n",
        "# Val Setup\n",
        "val_dir = \"val_data\"\n",
        "val_size = 12800\n",
        "# os.mkdir(base + val_dir)\n",
        "\n",
        "#   Addressing Files\n",
        "baseTake = base_dir\n",
        "# baseTake = base + base_dir\n",
        "basePutTrain = base + train_dir\n",
        "basePutVal = base + val_dir\n",
        "\n",
        "#   Val Takes\n",
        "for i in range(val_size):\n",
        "    random_image_label = random.choice(list(files.keys()))\n",
        "    random_image_label_file = random_image_label + '.png'\n",
        "    os.replace(os.path.join(baseTake, random_image_label_file), os.path.join(basePutVal, random_image_label_file))\n",
        "    files.pop(random_image_label)\n",
        "\n",
        "#   Train Takes\n",
        "for x in files:\n",
        "    # x = random.choice(list(files.keys()))\n",
        "    label = x + '.png'\n",
        "    os.replace(os.path.join(baseTake, label), os.path.join(basePutTrain, label))\n",
        "\n",
        "# Check Size - Test\n",
        "base_list = os.listdir(base_dir)\n",
        "print('base len = ' + str(len(base_list)))\n",
        "# Check Size - Train\n",
        "train_list = os.listdir(train_dir)\n",
        "print('train_data len = ' + str(len(train_list)))\n",
        "# Check Size - Val\n",
        "val_list = os.listdir(val_dir)\n",
        "print('val_list len = ' + str(len(val_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcKsswbLGJK",
        "outputId": "b1f9e51a-0d08-4a64-8dec-371f0b5fc785"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Converter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def main(model_name):\n",
        "    with open(f'/content/{model_name}.json') as f:\n",
        "        model = f.read()\n",
        "    model = keras.models.model_from_json(model)\n",
        "    model.load_weights(f'/content/{model_name}.h5')\n",
        "    cvt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite = cvt.convert()\n",
        "    with open(f'/content/drive/MyDrive/Year V/converted_{model_name}.tflite', 'wb') as f:\n",
        "        f.write(tflite)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = 'test'\n",
        "    main(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVVklkiDGy_"
      },
      "source": [
        "#   Classify\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    model_name = '/content/train_model_01'\n",
        "    captcha_dir = '/content/testers_5_lowercase'\n",
        "    output = '/content/output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        with open(output, 'w') as output_file:\n",
        "            json_file = open(model_name+'.json', 'r')\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            model = keras.models.model_from_json(loaded_model_json)\n",
        "            model.load_weights(model_name+'_resume.h5')\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            for x in os.listdir(captcha_dir):\n",
        "                # load image and preprocess it\n",
        "                raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "\n",
        "                #   Preprocess Image\n",
        "                image = preprocess(raw_data)\n",
        "\n",
        "                prediction = model.predict(image)\n",
        "                predictedAnswer = decode(captcha_symbols, prediction)\n",
        "                output_file.write(x + \", \" + predictedAnswer + \"\\n\")\n",
        "\n",
        "                print('Classified ' + x + '///' + predictedAnswer)\n",
        "\n",
        "                answer = x[:-4]\n",
        "                if (answer == predictedAnswer) :\n",
        "                    correct = correct + 1\n",
        "                else :\n",
        "                    incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D5HK4YIc-t"
      },
      "source": [
        "# Classify - Lite\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=1)\n",
        "    #y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    \n",
        "    model_name = '/content/converted_test.tflite'\n",
        "    captcha_dir = '/content/testers_4_characters_no_lowercase'\n",
        "    output = '/content/converted_4_output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "# Pi Addresses\n",
        "    # model_name = '/users/ugrad/brennar5/captcha_detection/converted_test.tflite'\n",
        "    # captcha_dir = '/users/ugrad/brennar5/captcha_detection/testers_4'\n",
        "    # output = '/users/ugrad/brennar5/captcha_detection/converted_4_output.csv'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    # captcha_symbols = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with open(output, 'w') as output_file:\n",
        "        \n",
        "        tf_interpreter = tflite.Interpreter(model_name)\n",
        "        tf_interpreter.allocate_tensors()\n",
        "        input_tf = tf_interpreter.get_input_details()\n",
        "        output_tf = tf_interpreter.get_output_details()\n",
        "        # print(input_tf)\n",
        "        # print(output_tf)\n",
        "\n",
        "        files = os.listdir(captcha_dir)\n",
        "        files = sorted(files)\n",
        "\n",
        "        for x in files:\n",
        "            # Load & Preprocess Image - Currently to work with test\n",
        "            raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "            rgb_data = cv2.cvtColor(raw_data, cv2.COLOR_BGR2RGB)\n",
        "            image = np.array(rgb_data, dtype=np.float32) / 255.0\n",
        "            (c, h, w) = image.shape\n",
        "            image = image.reshape([-1, c, h, w])\n",
        "            \n",
        "            tf_interpreter.set_tensor(input_tf[0]['index'],image)\n",
        "            tf_interpreter.invoke()\n",
        "            prediction = []\n",
        "            for output_node in output_tf:\n",
        "                prediction.append(tf_interpreter.get_tensor(output_node['index']))\n",
        "            prediction = np.reshape(prediction,(len(output_tf),-1))\n",
        "            decoded_symbol = decode(captcha_symbols, prediction)\n",
        "            output_file.write(x + \",\" + decoded_symbol + \"\\n\")\n",
        "            \n",
        "            print('Classified ' + x + '///' + decoded_symbol)\n",
        "\n",
        "            answer = x[:-4]\n",
        "            if (answer == decoded_symbol) :\n",
        "                correct = correct + 1\n",
        "            else :\n",
        "                incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}