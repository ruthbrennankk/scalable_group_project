{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of captcha_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthbrennankk/scalable_group_project/blob/master/Copy_of_captcha_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmP7l_S8Bax1"
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import scipy.ndimage\n",
        "import random\n",
        "import captcha.image\n",
        "\n",
        "from PIL import Image\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import shutil\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi30LY3zCvY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc55e464-d14c-4d67-d4d0-2b44c49c0ea3"
      },
      "source": [
        "!pip3 install --index-url https://google-coral.github.io/py-repo/ tflite_runtime\n",
        "!pip install captcha\n",
        "!pip install stsci.ndimage"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://google-coral.github.io/py-repo/\n",
            "Collecting tflite_runtime\n",
            "  Downloading https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n",
            "Installing collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.5.0.post1\n",
            "Collecting captcha\n",
            "  Downloading captcha-0.3-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from captcha) (7.1.2)\n",
            "Installing collected packages: captcha\n",
            "Successfully installed captcha-0.3\n",
            "Collecting stsci.ndimage\n",
            "  Downloading stsci.ndimage-0.10.3.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.5.1 in /usr/local/lib/python3.7/dist-packages (from stsci.ndimage) (1.19.5)\n",
            "Building wheels for collected packages: stsci.ndimage\n",
            "  Building wheel for stsci.ndimage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stsci.ndimage: filename=stsci.ndimage-0.10.3-cp37-cp37m-linux_x86_64.whl size=235557 sha256=8d06effac15e70b308d1a5760d54e6e09add781216d481c1289df9e15f77e21b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/f6/da/e57766b5a06db608d4b613aa9124957d95b072367bab3aafef\n",
            "Successfully built stsci.ndimage\n",
            "Installing collected packages: stsci.ndimage\n",
            "Successfully installed stsci.ndimage-0.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hrYMIRvCwRN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fe847523-999a-4e21-b8f4-7fb5adc37ad1"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmDkPlwlhV5e"
      },
      "source": [
        "captcha_symbols=\"0123456789ceghijknpoqsuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\-|_ \"  # I didn't see it in mine but potentially '\\'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygfxS5RzBerO"
      },
      "source": [
        "# Preprocess\n",
        "def preprocess(raw_data) :\n",
        "    return smallPreprocess(raw_data)\n",
        "\n",
        "def erase_circles(img, circles):\n",
        "    circles = circles[0]  # hough circles returns a nested list for some reason\n",
        "    for circle in circles:\n",
        "        center = (round(circle[0]),round(circle[1]))\n",
        "        img = cv2.circle(img, center, radius=round(circle[2]), color=255, thickness=1)  # erase circle by making it white (to match the image background)\n",
        "    return img\n",
        "\n",
        "def detect_and_remove_circles(img):\n",
        "    hough_circle_locations = cv2.HoughCircles(img, method=cv2.HOUGH_GRADIENT, dp=1, minDist=1, param1=50, param2=5, minRadius=0, maxRadius=2)\n",
        "    if hough_circle_locations is not None:\n",
        "        img = erase_circles(img, hough_circle_locations)\n",
        "    return img\n",
        "\n",
        "def smallPreprocess(raw_data):\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY) # Gray Image\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) # Back to Colour for channel\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    image = image.reshape([-1, c, h, w])\n",
        "    return image\n",
        "\n",
        "def bigPreprocess(raw_data) :\n",
        "    #   Back to Black\n",
        "    img = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "    # run some basic tests to get rid of easy-to-remove noise -- first pass\n",
        "    img = ~img  # white letters, black background\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # weaken circle noise and line noise\n",
        "    img = ~img  # black letters, white background\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # remove line noise\n",
        "    img = scipy.ndimage.median_filter(img, (1, 3))  # weaken circle noise\n",
        "    img = cv2.erode(img, np.ones((2, 2), np.uint8), iterations=1)  # dilate image to initial stage (erode works similar to dilate because we thresholded the image the opposite way)\n",
        "    img = scipy.ndimage.median_filter(img, (3, 3))  # remove any final 'weak' noise that might be present (line or circle)\n",
        "    # detect any remaining circle noise\n",
        "    img = detect_and_remove_circles(img)  # after dilation, if concrete circles exist, use hough transform to remove them\n",
        "    # eradicate any final noise that wasn't removed previously -- second pass\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # actually performs erosion\n",
        "    img = scipy.ndimage.median_filter(img, (5, 1))  # finally completely remove any extra noise that remains\n",
        "    img = cv2.erode(img, np.ones((3, 3), np.uint8), iterations=2)  # dilate image to make it look like the original\n",
        "    img = cv2.dilate(img, np.ones((3, 3), np.uint8), iterations=1)  # erode just a bit to polish fine details\n",
        "    #Edge Detection\n",
        "    # img = cv2.Canny(img, 100, 200)\n",
        "    # Back to Colour\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Format - (different for pi)\n",
        "    image = np.array(img) / 255.0\n",
        "    (c, h, w) = image.shape\n",
        "    return image.reshape([-1, c, h, w])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct97WoykCWlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8df1e5d8-4528-4922-d12b-7be9c55b5b36"
      },
      "source": [
        "# Train\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Build a Keras model given some parameters\n",
        "def create_model(captcha_length, captcha_num_symbols, input_shape, model_depth=5, module_size=2):\n",
        "  input_tensor = keras.Input(input_shape)\n",
        "  x = input_tensor\n",
        "  for i, module_length in enumerate([module_size] * model_depth): \n",
        "      for j in range(module_length):\n",
        "          x = keras.layers.Conv2D(32*2**min(i, 3), kernel_size=3, padding='same', kernel_initializer='he_uniform')(x)\n",
        "          x = keras.layers.BatchNormalization()(x)\n",
        "          x = keras.layers.Activation('relu')(x)\n",
        "      x = keras.layers.MaxPooling2D(2)(x)\n",
        "\n",
        "  x = keras.layers.Flatten()(x)\n",
        "  x = [keras.layers.Dense(captcha_num_symbols, activation='softmax', name='char_%d'%(i+1))(x) for i in range(captcha_length)]\n",
        "  model = keras.Model(inputs=input_tensor, outputs=x)\n",
        "\n",
        "  return model\n",
        "\n",
        "# A Sequence represents a dataset for training in Keras\n",
        "# In this case, we have a folder full of images\n",
        "# Elements of a Sequence are *batches* of images, of some size batch_size\n",
        "class ImageSequence(keras.utils.Sequence):\n",
        "    def __init__(self, directory_name, batch_size, label_file, captcha_symbols, captcha_width, captcha_height):\n",
        "        self.directory_name = directory_name\n",
        "        self.batch_size = batch_size\n",
        "        self.captcha_length = 6\n",
        "        self.captcha_symbols = captcha_symbols\n",
        "        self.captcha_width = captcha_width\n",
        "        self.captcha_height = captcha_height\n",
        "        self.label_file = label_file\n",
        "        file_list = os.listdir(self.directory_name)\n",
        "        with open(self.label_file,\"+r\") as f:\n",
        "          labelList = f.readlines()\n",
        "          self.files = dict(zip(map(lambda x:x.split(\",\")[0],labelList),map(lambda x:x.split(\",\")[1].strip(\"\\n\"),labelList)))\n",
        "        self.used_files = []\n",
        "        self.count = len(file_list)\n",
        "    def __len__(self):\n",
        "        return int(np.floor(self.count / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        X = np.zeros((self.batch_size, self.captcha_height, self.captcha_width, 1), dtype=np.float32)\n",
        "        y = [np.zeros((self.batch_size, len(self.captcha_symbols)), dtype=np.uint8) for i in range(self.captcha_length)]\n",
        "\n",
        "        for i in range(min(self.batch_size, len(self.files))):\n",
        "            random_image_file = random.choice(list(self.files.keys()))\n",
        "            random_image_label = self.files[random_image_file]\n",
        "            # We've used this image now, so we can't repeat it in this iteration\n",
        "            #self.used_files.append(self.files.pop(random_image_label))\n",
        "\n",
        "            # We have to scale the input pixel values to the range [0, 1] for\n",
        "            # Keras so we divide by 255 since the image is 8-bit RGB\n",
        "            raw_data = cv2.imread(os.path.join(self.directory_name, random_image_file))\n",
        "            rgb_data = cv2.cvtColor(raw_data, cv2.COLOR_BGR2GRAY)\n",
        "            ret, thresh1 = cv2.threshold(rgb_data, 120, 255, cv2.THRESH_BINARY + \n",
        "                                            cv2.THRESH_OTSU)\n",
        "            #cv2.imshow('Otsu Threshold', thresh1)\n",
        "            thresh1 = cv2.bitwise_not(thresh1)\n",
        "            kernel = np.ones((2,2),np.uint8)\n",
        "            opening = cv2.morphologyEx(thresh1, cv2.MORPH_OPEN, kernel)\n",
        "            opening = cv2.medianBlur(opening,3)\n",
        "            #processed_data = numpy.array(rgb_data) / 255.0\n",
        "            processed_data=np.array(opening)\n",
        "            processed_data = processed_data[:, :, np.newaxis]\n",
        "            X[i] = processed_data\n",
        "            for j, ch in enumerate(random_image_label):\n",
        "                y[j][i, :] = 0\n",
        "                y[j][i, self.captcha_symbols.find(ch)] = 1\n",
        "        return X, y\n",
        "\n",
        "def main():\n",
        "    # inputs\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6 \n",
        "    symbols = 'symbols.txt'\n",
        "    batch_size = 32\n",
        "    epochs = 5\n",
        "    output_model_name = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/model04'\n",
        "    validate_outputFile = '/content/validation_lables.txt'\n",
        "    validate_dataset = '/content/validation_data/'\n",
        "    train_dataset = '/content/training_data/'\n",
        "    train_outputFile = '/content/training_lables.txt'\n",
        "    captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\-|_ \"\n",
        "    # captcha_symbols = None\n",
        "    # with open(symbols) as symbols_file:\n",
        "    #     captcha_symbols = symbols_file.readline()\n",
        "\n",
        "    with tf.device('/device:GPU:0'):\n",
        "        model = create_model(length, len(captcha_symbols), (height, width, 1))\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy',\n",
        "                      optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        training_data = ImageSequence(train_dataset, batch_size,train_outputFile, captcha_symbols, width, height)\n",
        "        validation_data = ImageSequence(validate_dataset, batch_size, validate_outputFile, captcha_symbols, width, height)\n",
        "\n",
        "        callbacks = [keras.callbacks.EarlyStopping(patience=3),\n",
        "                     # keras.callbacks.CSVLogger('log.csv'),\n",
        "                     keras.callbacks.ModelCheckpoint(output_model_name+'.h5', save_best_only=False)]\n",
        "\n",
        "        # Save the model architecture to JSON\n",
        "        with open(output_model_name+\".json\", \"w\") as json_file:\n",
        "            json_file.write(model.to_json())\n",
        "\n",
        "        try:\n",
        "            model.fit_generator(generator=training_data,\n",
        "                                validation_data=validation_data,\n",
        "                                epochs=epochs,\n",
        "                                callbacks=callbacks,\n",
        "                                use_multiprocessing=True)\n",
        "        except KeyboardInterrupt:\n",
        "            print('KeyboardInterrupt caught, saving current weights as ' + output_model_name+'_resume.h5')\n",
        "            model.save_weights(output_model_name+'_resume.h5')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 64, 128, 1)] 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 128, 32)  320         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 64, 128, 32)  128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 64, 128, 32)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 128, 32)  9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 64, 128, 32)  128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 64, 128, 32)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 32, 64, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 32, 64, 64)   18496       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 32, 64, 64)   256         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 32, 64, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 32, 64, 64)   36928       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 32, 64, 64)   256         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 32, 64, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 16, 32, 64)   0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 32, 128)  73856       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 32, 128)  512         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 32, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 32, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 32, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 32, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 8, 16, 128)   0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 16, 256)   295168      max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 16, 256)   1024        conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 16, 256)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 16, 256)   590080      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 16, 256)   1024        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 16, 256)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 4, 8, 256)    0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 4, 8, 256)    590080      max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 4, 8, 256)    1024        conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 4, 8, 256)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 4, 8, 256)    590080      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 4, 8, 256)    1024        conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 4, 8, 256)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2D)  (None, 2, 4, 256)    0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           max_pooling2d_9[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "char_1 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_2 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_3 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_4 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_5 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "char_6 (Dense)                  (None, 65)           133185      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,156,838\n",
            "Trainable params: 3,153,894\n",
            "Non-trainable params: 2,944\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1472/7812 [====>.........................] - ETA: 21:00 - loss: 12.1651 - char_1_loss: 2.5289 - char_2_loss: 2.7786 - char_3_loss: 2.5498 - char_4_loss: 2.0310 - char_5_loss: 1.4476 - char_6_loss: 0.8292 - char_1_accuracy: 0.3658 - char_2_accuracy: 0.3345 - char_3_accuracy: 0.4073 - char_4_accuracy: 0.5376 - char_5_accuracy: 0.6827 - char_6_accuracy: 0.8345"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j23CCojr1n4n",
        "outputId": "64341592-960a-4a7d-ea11-a1ef78d1130e"
      },
      "source": [
        "# with open('/content/drive/My Drive/foo.txt', '+w') as f:\n",
        "#   f.write('Hello Google Drive!')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TU9lkzH--UWW",
        "outputId": "537043b0-6d04-40f9-efe3-192c3e483f9d"
      },
      "source": [
        "!ls /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive\t     training_data\t  validation_data\n",
            "sample_data  training_lables.txt  validation_lables.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "yylOZXxb2vH-",
        "outputId": "f4132350-9c1c-4846-e0a3-78a22b5d10bf"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/model02')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-540a5e90a25d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model02'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=undefined-variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m   \u001b[0mcomm_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_IPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomm_manager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find file: /content/model02"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCb_El-5FK9D",
        "outputId": "e6c9b854-a519-4a77-8e47-31040802e8e3"
      },
      "source": [
        "raw_data = cv2.imread(os.path.join('/content/training_data/', 'img_1209.png'))\n",
        "print(raw_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]]\n",
            "\n",
            " [[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]]\n",
            "\n",
            " [[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [226 235 237]\n",
            "  [133 124 116]\n",
            "  [ 66  45  29]]\n",
            "\n",
            " [[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [226 235 237]\n",
            "  [199 203 202]\n",
            "  [ 66  45  29]]\n",
            "\n",
            " [[239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  ...\n",
            "  [239 251 254]\n",
            "  [239 251 254]\n",
            "  [239 251 254]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dI9wdAiCqTY",
        "outputId": "117f9b38-bba7-4207-9b88-2d4e3ef52b8b"
      },
      "source": [
        "# Generate\n",
        "#!/usr/bin/env python3\n",
        "def main():\n",
        "    width = 128\n",
        "    height = 64\n",
        "    length = 6\n",
        "    count = 250000 #100 #140800 #128000 - 40m\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/test_set' #test set\n",
        "    # output_dir = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/train_set' #training set\n",
        "    outputFile = '/content/training_lables.txt'\n",
        "    output_dir = '/content/training_data/' #validation set\n",
        "    # Appedning symbol set with \\ and -\n",
        "    # 15.21 - time\n",
        "    captcha_symbols=\"0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\-|_\" # I didn't see it in mine but potentially '\\'    # symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/symbols.txt'\n",
        "    # for x in range(0, 9):\n",
        "    #   captcha_symbols = captcha_symbols + ' '\n",
        "\n",
        "    captcha_generator = captcha.image.ImageCaptcha(width=width, height=height)\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Generating captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "        print(\"Creating output directory \" + output_dir)\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    filenames = []\n",
        "    index = 0\n",
        "  \n",
        "    for i in range(count):\n",
        "        caplength = np.random.randint(1,7)\n",
        "        random_str = ''.join([random.choice(captcha_symbols) for j in range(caplength)])\n",
        "        img_name = 'img_'+str(i)+'.png'\n",
        "        image_path = os.path.join(output_dir, img_name)\n",
        "        if os.path.exists(image_path):\n",
        "            version = 1\n",
        "            while os.path.exists(os.path.join(output_dir, random_str + '_' + str(version) + '.png')):\n",
        "                version += 1\n",
        "            image_path = os.path.join(output_dir, random_str + '_' + str(version) + '.png')\n",
        "\n",
        "        image = np.array(captcha_generator.generate_image(random_str))\n",
        "        if(caplength < 6 or len(random_str) < 6):\n",
        "              random_str = random_str.ljust(6,' ')\n",
        "        cv2.imwrite(image_path, image)\n",
        "        with open(outputFile,'a+') as f:\n",
        "            f.write(img_name + \",\" + random_str + \"\\n\")\n",
        "\n",
        "    # for i in range(count):\n",
        "    #     random_str = ''.join([random.choice(captcha_symbols) for j in range(length)])\n",
        "\n",
        "    #     filenames.append(random_str)\n",
        "\n",
        "    #     image_path = os.path.join(output_dir, str(index)+'.png')\n",
        "        \n",
        "    #     if os.path.exists(image_path):\n",
        "    #         version = 1\n",
        "    #         while os.path.exists(os.path.join(output_dir, str(index) + '_' + str(version) + '.png')):\n",
        "    #             version += 1\n",
        "    #         image_path = os.path.join(output_dir, str(index) + '_' + str(version) + '.png')\n",
        "\n",
        "    #     image = np.array(captcha_generator.generate_image(random_str))\n",
        "    #     cv2.imwrite(image_path, image)\n",
        "    #     index = index + 1\n",
        "\n",
        "    # pd.DataFrame(filenames).to_csv(\"/content/drive/MyDrive/Year V/Scalable Computing/Practical 2/validation_set_names.csv\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating captchas with symbol set {0123456789ceghijklnpoqstuvwxyzABCDFJKMPQRSTUVWXYZ#[]+:></%{}\\-|_}\n",
            "Creating output directory /content/training_data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bANHumMjC0l6"
      },
      "source": [
        "#@title\n",
        "# Move Files\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# base = \"/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/\"\n",
        "base = '/content/'\n",
        "base_dir = '/content/drive/MyDrive/MS/Sem1/Scalable Computing/Project2/training_data'\n",
        "# files setup\n",
        "file_list = os.listdir(base_dir)\n",
        "files = dict(zip(map(lambda x: x.split('.')[0], file_list), file_list))\n",
        "print('base len = ' + str(len(files)))\n",
        "\n",
        "# Train Setup\n",
        "train_dir = \"train_data\"\n",
        "# os.mkdir(base + train_dir)\n",
        "\n",
        "# Val Setup\n",
        "val_dir = \"val_data\"\n",
        "val_size = 12800\n",
        "# os.mkdir(base + val_dir)\n",
        "\n",
        "#   Addressing Files\n",
        "baseTake = base_dir\n",
        "# baseTake = base + base_dir\n",
        "basePutTrain = base + train_dir\n",
        "basePutVal = base + val_dir\n",
        "\n",
        "#   Val Takes\n",
        "for i in range(val_size):\n",
        "    random_image_label = random.choice(list(files.keys()))\n",
        "    random_image_label_file = random_image_label + '.png'\n",
        "    os.replace(os.path.join(baseTake, random_image_label_file), os.path.join(basePutVal, random_image_label_file))\n",
        "    files.pop(random_image_label)\n",
        "\n",
        "#   Train Takes\n",
        "for x in files:\n",
        "    # x = random.choice(list(files.keys()))\n",
        "    label = x + '.png'\n",
        "    os.replace(os.path.join(baseTake, label), os.path.join(basePutTrain, label))\n",
        "\n",
        "# Check Size - Test\n",
        "base_list = os.listdir(base_dir)\n",
        "print('base len = ' + str(len(base_list)))\n",
        "# Check Size - Train\n",
        "train_list = os.listdir(train_dir)\n",
        "print('train_data len = ' + str(len(train_list)))\n",
        "# Check Size - Val\n",
        "val_list = os.listdir(val_dir)\n",
        "print('val_list len = ' + str(len(val_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8IcKsswbLGJK",
        "outputId": "b1f9e51a-0d08-4a64-8dec-371f0b5fc785"
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# Converter\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "def main(model_name):\n",
        "    with open(f'/content/{model_name}.json') as f:\n",
        "        model = f.read()\n",
        "    model = keras.models.model_from_json(model)\n",
        "    model.load_weights(f'/content/{model_name}.h5')\n",
        "    cvt = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    tflite = cvt.convert()\n",
        "    with open(f'/content/drive/MyDrive/Year V/converted_{model_name}.tflite', 'wb') as f:\n",
        "        f.write(tflite)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    model_name = 'test'\n",
        "    main(model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpi20stg_4/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biVVklkiDGy_"
      },
      "source": [
        "#   Classify\n",
        "#!/usr/bin/env python3\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    model_name = '/content/train_model_01'\n",
        "    captcha_dir = '/content/testers_5_lowercase'\n",
        "    output = '/content/output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with tf.device('/cpu:0'):\n",
        "        with open(output, 'w') as output_file:\n",
        "            json_file = open(model_name+'.json', 'r')\n",
        "            loaded_model_json = json_file.read()\n",
        "            json_file.close()\n",
        "            model = keras.models.model_from_json(loaded_model_json)\n",
        "            model.load_weights(model_name+'_resume.h5')\n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer=keras.optimizers.Adam(1e-3, amsgrad=True),\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            for x in os.listdir(captcha_dir):\n",
        "                # load image and preprocess it\n",
        "                raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "\n",
        "                #   Preprocess Image\n",
        "                image = preprocess(raw_data)\n",
        "\n",
        "                prediction = model.predict(image)\n",
        "                predictedAnswer = decode(captcha_symbols, prediction)\n",
        "                output_file.write(x + \", \" + predictedAnswer + \"\\n\")\n",
        "\n",
        "                print('Classified ' + x + '///' + predictedAnswer)\n",
        "\n",
        "                answer = x[:-4]\n",
        "                if (answer == predictedAnswer) :\n",
        "                    correct = correct + 1\n",
        "                else :\n",
        "                    incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9D5HK4YIc-t"
      },
      "source": [
        "# Classify - Lite\n",
        "#!/usr/bin/env python3\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tflite_runtime.interpreter as tflite\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "def decode(characters, y):\n",
        "    y = np.argmax(np.array(y), axis=1)\n",
        "    #y = np.argmax(np.array(y), axis=2)[:,0]\n",
        "    return ''.join([characters[x] for x in y])\n",
        "\n",
        "def main():\n",
        "    \n",
        "    model_name = '/content/converted_test.tflite'\n",
        "    captcha_dir = '/content/testers_4_characters_no_lowercase'\n",
        "    output = '/content/converted_4_output.csv'\n",
        "    symbols = '/content/drive/MyDrive/Year V/Scalable Computing/Practical 1/symbols.txt'\n",
        "\n",
        "# Pi Addresses\n",
        "    # model_name = '/users/ugrad/brennar5/captcha_detection/converted_test.tflite'\n",
        "    # captcha_dir = '/users/ugrad/brennar5/captcha_detection/testers_4'\n",
        "    # output = '/users/ugrad/brennar5/captcha_detection/converted_4_output.csv'\n",
        "\n",
        "    # symbols_file = open(symbols, 'r')\n",
        "    # captcha_symbols = symbols_file.readline().strip()\n",
        "    # symbols_file.close()\n",
        "\n",
        "    # captcha_symbols = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    print(\"Classifying captchas with symbol set {\" + captcha_symbols + \"}\")\n",
        "    correct = 0\n",
        "    incorrect = 0\n",
        "\n",
        "    with open(output, 'w') as output_file:\n",
        "        \n",
        "        tf_interpreter = tflite.Interpreter(model_name)\n",
        "        tf_interpreter.allocate_tensors()\n",
        "        input_tf = tf_interpreter.get_input_details()\n",
        "        output_tf = tf_interpreter.get_output_details()\n",
        "        # print(input_tf)\n",
        "        # print(output_tf)\n",
        "\n",
        "        files = os.listdir(captcha_dir)\n",
        "        files = sorted(files)\n",
        "\n",
        "        for x in files:\n",
        "            # Load & Preprocess Image - Currently to work with test\n",
        "            raw_data = cv2.imread(os.path.join(captcha_dir, x))\n",
        "            rgb_data = cv2.cvtColor(raw_data, cv2.COLOR_BGR2RGB)\n",
        "            image = np.array(rgb_data, dtype=np.float32) / 255.0\n",
        "            (c, h, w) = image.shape\n",
        "            image = image.reshape([-1, c, h, w])\n",
        "            \n",
        "            tf_interpreter.set_tensor(input_tf[0]['index'],image)\n",
        "            tf_interpreter.invoke()\n",
        "            prediction = []\n",
        "            for output_node in output_tf:\n",
        "                prediction.append(tf_interpreter.get_tensor(output_node['index']))\n",
        "            prediction = np.reshape(prediction,(len(output_tf),-1))\n",
        "            decoded_symbol = decode(captcha_symbols, prediction)\n",
        "            output_file.write(x + \",\" + decoded_symbol + \"\\n\")\n",
        "            \n",
        "            print('Classified ' + x + '///' + decoded_symbol)\n",
        "\n",
        "            answer = x[:-4]\n",
        "            if (answer == decoded_symbol) :\n",
        "                correct = correct + 1\n",
        "            else :\n",
        "                incorrect = incorrect + 1\n",
        "\n",
        "    print('correct = '+str(correct))\n",
        "    print('incorrect ='+str(incorrect))\n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}